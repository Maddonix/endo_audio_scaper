{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84a2d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a575ab2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5923890579e748ffa425bea43c2be575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = pathlib.Path(\"../scaper/soundscapes/train\")\n",
    "wav_paths = [_ for _ in data_path.iterdir() if _.suffix == \".wav\"]\n",
    "label_paths = [_.with_suffix(\".txt\") for _ in wav_paths]\n",
    "\n",
    "labels = [utils.read_label_txt(_)[\"label\"].to_list() for _ in tqdm(label_paths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95f333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "label_array = mlb.fit_transform(labels)\n",
    "classes = mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb8a0d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alarm_bell_ringing', 'Cat', 'Dishes', 'Dog',\n",
       "       'Electric_shaver_toothbrush'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a7f143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {\n",
    "    \"relative_path\": [_.name for _ in wav_paths],\n",
    "    \"class_ids\": [_ for _ in label_array]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0284d61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_path</th>\n",
       "      <th>class_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_unimodal4241.wav</td>\n",
       "      <td>[0, 1, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_unimodal1544.wav</td>\n",
       "      <td>[0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_unimodal5168.wav</td>\n",
       "      <td>[0, 0, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_unimodal5422.wav</td>\n",
       "      <td>[0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_unimodal3289.wav</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 relative_path        class_ids\n",
       "0  soundscape_unimodal4241.wav  [0, 1, 1, 0, 1]\n",
       "1  soundscape_unimodal1544.wav  [0, 0, 1, 1, 0]\n",
       "2  soundscape_unimodal5168.wav  [0, 0, 0, 1, 1]\n",
       "3  soundscape_unimodal5422.wav  [0, 0, 1, 1, 0]\n",
       "4  soundscape_unimodal3289.wav  [0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa952996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import torch.optim \n",
    "from utils import SoundDS\n",
    "from torch.utils.data import random_split\n",
    "from models import AudioClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f06b2c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "myds = SoundDS(df, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a408aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Val Split\n",
    "\n",
    "num_items = len(myds)\n",
    "num_train = round(num_items * 0.8)\n",
    "num_val = num_items - num_train\n",
    "batch_size = 50\n",
    "\n",
    "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ed25263",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d113eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AudioClassifier()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb241f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:34igewd5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 6964<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/lux_t1/Desktop/endo_audio_scaper/network/wandb/run-20210420_090343-34igewd5/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/lux_t1/Desktop/endo_audio_scaper/network/wandb/run-20210420_090343-34igewd5/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">lunar-meadow-1</strong>: <a href=\"https://wandb.ai/maddonix/endomic/runs/34igewd5\" target=\"_blank\">https://wandb.ai/maddonix/endomic/runs/34igewd5</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:34igewd5). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.27<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">earthy-waterfall-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/maddonix/endomic\" target=\"_blank\">https://wandb.ai/maddonix/endomic</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/maddonix/endomic/runs/326c6gpn\" target=\"_blank\">https://wandb.ai/maddonix/endomic/runs/326c6gpn</a><br/>\n",
       "                Run data is saved locally in <code>/home/lux_t1/Desktop/endo_audio_scaper/network/wandb/run-20210420_090416-326c6gpn</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# 1. Start a new run\n",
    "wandb.init(project='endomic', entity='maddonix')\n",
    "\n",
    "# 2. Save model inputs and hyperparameters\n",
    "config = wandb.config\n",
    "# config.learning_rate = 0.01\n",
    "\n",
    "\n",
    "\n",
    "# # 3. Log gradients and model parameters\n",
    "# wandb.watch(model)\n",
    "# for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#   ...\n",
    "#   if batch_idx % args.log_interval == 0:\n",
    "#     # 4. Log metrics to visualize performance\n",
    "#     wandb.log({\"loss\": loss})\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca7655e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Training Loop\n",
    "# ----------------------------\n",
    "def training(model, train_dl, num_epochs, classes):\n",
    "    wandb.init(project='endomic', entity='maddonix')\n",
    "    config = wandb.config\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                steps_per_epoch=int(len(train_dl)),\n",
    "                                                epochs=num_epochs,\n",
    "                                                anneal_strategy='linear')\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    # Repeat for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_prediction = np.zeros((n_classes))\n",
    "        total_prediction = 0\n",
    "\n",
    "        # Repeat for each batch in the training set\n",
    "        for i, data in enumerate(train_dl):\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.type_as(outputs))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Keep stats for Loss and Accuracy\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Get the predicted classes with threshold > 0.5\n",
    "#             _, prediction = torch.max(outputs,1)\n",
    "            outputs[outputs>0.5] = 1\n",
    "            outputs[outputs<=0.5] = 0\n",
    "            prediction = outputs\n",
    "            \n",
    "            # Count of predictions that matched the target label\n",
    "#             print(prediction.shape)\n",
    "#             print(labels.shape)\n",
    "#             print((prediction==labels).shape)\n",
    "#             return prediction == labels\n",
    "            correct_prediction += (prediction == labels).sum(axis = 0).cpu().numpy()\n",
    "            total_prediction += prediction.shape[0]\n",
    "\n",
    "#             if i % 10 == 0 and i > 0:    # print every 10 mini-batches\n",
    "#                 print(f'Epoch: {epoch}, iteration: {i+1} loss: {running_loss / (i * 100)}')\n",
    "\n",
    "        # Print stats at the end of the epoch\n",
    "        num_batches = len(train_dl)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        acc = correct_prediction/(total_prediction*n_classes)\n",
    "        wandb.log({\n",
    "            \"loss\": loss,\n",
    "            \"acc\": {_: acc[i] for i, _ in enumerate(classes)}\n",
    "        })\n",
    "        \n",
    "        \n",
    "        print(f'Epoch: {epoch}, Loss: {avg_loss}, Accuracy: {acc}')\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4805275e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:326c6gpn) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7016<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.01MB of 0.01MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/lux_t1/Desktop/endo_audio_scaper/network/wandb/run-20210420_090416-326c6gpn/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/lux_t1/Desktop/endo_audio_scaper/network/wandb/run-20210420_090416-326c6gpn/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">earthy-waterfall-2</strong>: <a href=\"https://wandb.ai/maddonix/endomic/runs/326c6gpn\" target=\"_blank\">https://wandb.ai/maddonix/endomic/runs/326c6gpn</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:326c6gpn). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.27<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">light-sound-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/maddonix/endomic\" target=\"_blank\">https://wandb.ai/maddonix/endomic</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/maddonix/endomic/runs/3ownnczo\" target=\"_blank\">https://wandb.ai/maddonix/endomic/runs/3ownnczo</a><br/>\n",
       "                Run data is saved locally in <code>/home/lux_t1/Desktop/endo_audio_scaper/network/wandb/run-20210420_091253-3ownnczo</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6191074412316084, Accuracy: [0.13155  0.132525 0.135175 0.132975 0.17005 ]\n",
      "Epoch: 1, Loss: 0.574749032407999, Accuracy: [0.1329  0.13315 0.13555 0.13285 0.17225]\n",
      "Epoch: 2, Loss: 0.5406540913507343, Accuracy: [0.133175 0.133625 0.1355   0.13445  0.174275]\n",
      "Epoch: 3, Loss: 0.5268620289862156, Accuracy: [0.133125 0.1335   0.135525 0.136275 0.1762  ]\n",
      "Epoch: 4, Loss: 0.5141498684883118, Accuracy: [0.133625 0.133275 0.135475 0.13865  0.179525]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lux_t1/.conda/envs/endomic/lib/python3.8/site-packages/wandb/wandb_torch.py:198: UserWarning: Legacy tensor constructor is deprecated. Use: torch.tensor(...) for creating tensors from tensor-like objects; or torch.empty(...) for creating an uninitialized tensor with specific sizes. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_new.cpp:478.)\n",
      "  check = torch.cuda.FloatTensor(1).fill_(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.5060690386220813, Accuracy: [0.133675 0.1341   0.1354   0.14175  0.18035 ]\n",
      "Epoch: 6, Loss: 0.4990142021328211, Accuracy: [0.13405  0.133525 0.135725 0.14345  0.1821  ]\n",
      "Epoch: 7, Loss: 0.49378336872905493, Accuracy: [0.13465  0.13345  0.135275 0.145675 0.183425]\n",
      "Epoch: 8, Loss: 0.4910734578967094, Accuracy: [0.135375 0.134125 0.1355   0.1461   0.18245 ]\n",
      "Epoch: 9, Loss: 0.48805265314877033, Accuracy: [0.135225 0.134    0.135375 0.146825 0.183375]\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "training(model, train_dl, 10, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8a90ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dl, classes):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    n_classes = len(classes)\n",
    "    correct_prediction = np.zeros((n_classes))\n",
    "    total_prediction = 0\n",
    "\n",
    "    # Repeat for each batch in the training set\n",
    "    for i, data in enumerate(dl):\n",
    "        # Get the input features and target labels, and put them on the GPU\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # Normalize the inputs\n",
    "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "        inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.type_as(outputs))\n",
    "\n",
    "        # Keep stats for Loss and Accuracy\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Get the predicted classes with threshold > 0.5\n",
    "    #             _, prediction = torch.max(outputs,1)\n",
    "        outputs[outputs>0.5] = 1\n",
    "        outputs[outputs<=0.5] = 0\n",
    "        prediction = outputs\n",
    "\n",
    "        # Count of predictions that matched the target label\n",
    "        correct_prediction += (prediction == labels).sum(axis = 0).cpu().numpy()\n",
    "        total_prediction += prediction.shape[0]\n",
    "\n",
    "    # Print stats at the end of the epoch\n",
    "    num_batches = len(train_dl)\n",
    "    avg_loss = running_loss / num_batches\n",
    "    acc = correct_prediction/(total_prediction*n_classes)\n",
    "    acc_dict = {classes[j]: _ for j, _ in enumerate(acc)}\n",
    "    print(f'Loss: {avg_loss}, Accuracy: {acc_dict}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "586b2752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13218424748629332, Accuracy: {'Alarm_bell_ringing': 0.1343, 'Cat': 0.1339, 'Dishes': 0.1286, 'Dog': 0.1433, 'Electric_shaver_toothbrush': 0.1774}\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, val_dl, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37b4cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "model_path = pathlib.Path(\"test_model.pth\")\n",
    "torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a43e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
