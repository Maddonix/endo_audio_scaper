{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2f3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import utils\n",
    "import importlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b444f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21143152ca344fd481f81bf08ba3a0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n"
     ]
    }
   ],
   "source": [
    "# classes = ['Alarm_bell_ringing', 'Cat', 'Dishes', 'Dog', 'Electric_shaver_toothbrush']\n",
    "classes = [\"Cat\", \"Dog\"]\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config = {\n",
    "    \"sample_rate\": 44100,\n",
    "    \"n_mels\": 64,\n",
    "    \"n_fft\": 1024, \n",
    "    \"hop_len\": 512,\n",
    "    \"top_db\": 80,\n",
    "    \"n_mfcc\": 64,\n",
    "    \"classes\": classes,\n",
    "    \"data_path\": \"../scaper/soundscapes/train\",\n",
    "    \"duration\": 10000\n",
    "}\n",
    "\n",
    "df, classes = utils.get_dataset_dataframe(config[\"data_path\"])\n",
    "dataset = utils.SoundDataSet(df, melspec=False, **config)\n",
    "# Train / Val Split\n",
    "\n",
    "num_items = len(dataset)\n",
    "print(num_items)\n",
    "num_train = round(num_items * 0.9)\n",
    "num_val = num_items - num_train\n",
    "batch_size = 100\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [num_train, num_val])\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "726c3ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig, spec, class_ids, sr, path = dataset.get_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55102415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] 44100 ../scaper/soundscapes/train/soundscape_unimodal55.wav\n"
     ]
    }
   ],
   "source": [
    "print(class_ids, sr, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e9998f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff97b7a8f40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(spec.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "471cde0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class minimal_model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(minimal_model, self).__init__()\n",
    "        \n",
    "        self.spec = torchaudio.transforms.Spectrogram(\n",
    "            n_fft = config[\"n_fft\"],\n",
    "            power = 2, # 1 is energy, 2 is power\n",
    "            normalized = True\n",
    "        )\n",
    "        self.melspec = torchaudio.transforms.MelSpectrogram(\n",
    "                    sample_rate = config[\"sample_rate\"],\n",
    "                    n_fft = config[\"n_fft\"],\n",
    "                    win_length = config[\"n_fft\"]//2,\n",
    "                    hop_length = config[\"hop_len\"],\n",
    "                    n_mels = config[\"n_mels\"],\n",
    "                    normalized = True\n",
    "                )\n",
    "        self.amp_to_db = torchaudio.transforms.AmplitudeToDB(stype = \"power\", top_db = config[\"top_db\"])\n",
    "        \n",
    "        self.bn0 = nn.BatchNorm2d(1)\n",
    "        self.conv0 = nn.Conv2d(1, 64, (3,3))\n",
    "        self.conv1 = nn.Conv2d(64, 256, (3,3))\n",
    "        self.conv2 = nn.Conv2d(256, 256, (3,3))\n",
    "        self.fc = nn.Linear(23552, 2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.melspec(input)\n",
    "        x = self.amp_to_db(x)\n",
    "        \n",
    "        x = self.bn0(x)\n",
    "        x = self.conv0(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        x = nn.Dropout(p = 0.2)(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, (3,3))\n",
    "        x = nn.Dropout(p = 0.2)(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, (3,3))\n",
    "        x = nn.Dropout(p = 0.2)(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        out = self.fc(x)\n",
    "        \n",
    "#         out = torch.sigmoid(x)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c4e6975",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = minimal_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8230b031",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minimal_model(\n",
       "  (spec): Spectrogram()\n",
       "  (melspec): MelSpectrogram(\n",
       "    (spectrogram): Spectrogram()\n",
       "    (mel_scale): MelScale()\n",
       "  )\n",
       "  (amp_to_db): AmplitudeToDB()\n",
       "  (bn0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc): Linear(in_features=23552, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d047a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, num_epochs, classes):\n",
    "    wandb.init(project='endomic', entity='maddonix')\n",
    "    config = wandb.config\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss() # nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                steps_per_epoch=int(len(train_dl)),\n",
    "                                                epochs=num_epochs,\n",
    "                                                anneal_strategy='linear')\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    # Repeat for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_prediction = np.zeros((n_classes))\n",
    "        total_prediction = 0\n",
    "\n",
    "        # Repeat for each batch in the training set\n",
    "        for i, data in enumerate(train_dl):\n",
    "            model.train()\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.type_as(outputs))\n",
    "            loss.backward()\n",
    "#             print(loss)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Keep stats for Loss and Accuracy\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Get the predicted classes with threshold > 0.5\n",
    "            outputs[outputs>0.5] = 1\n",
    "            outputs[outputs<=0.5] = 0\n",
    "            prediction = outputs\n",
    "            \n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum(axis = 0).cpu().numpy()\n",
    "            total_prediction += prediction.shape[0]\n",
    "\n",
    "#             if i % 10 == 0 and i > 0:    # print every 10 mini-batches\n",
    "#                 print(f'Epoch: {epoch}, iteration: {i} loss: {running_loss / i}')\n",
    "\n",
    "        # Print stats at the end of the epoch\n",
    "        num_batches = len(train_dl)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        acc = correct_prediction/(total_prediction*n_classes)\n",
    "        acc_dict ={_: acc[i] for i, _ in enumerate(classes)}\n",
    "#         model.eval()\n",
    "#         val_loss, val_acc_dict = evaluate(model, val_dl, classes, criterion)\n",
    "        wandb.log({\n",
    "            \"train_loss\": loss,\n",
    "            \"train_acc\": acc_dict,\n",
    "#             \"val_loss\": val_loss,\n",
    "#             \"val_acc\": val_acc_dict\n",
    "        })        \n",
    "        \n",
    "        print(f'Epoch: {epoch}')\n",
    "        print(f'Train: Loss: {avg_loss}, Accuracy: {acc}')\n",
    "#         print(f'Val: Loss: {val_loss}, Accuracy: {val_acc_dict}')\n",
    "        \n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99f7aac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2jba1ul2) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11755<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/lux_t1/Desktop/endo_audio_scaper/network/wandb/run-20210422_145811-2jba1ul2/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/lux_t1/Desktop/endo_audio_scaper/network/wandb/run-20210422_145811-2jba1ul2/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>0.53961</td></tr><tr><td>_runtime</td><td>16</td></tr><tr><td>_timestamp</td><td>1619096310</td></tr><tr><td>_step</td><td>7</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss</td><td>▅▃▁▄▄▄█▆</td></tr><tr><td>_runtime</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">royal-pine-42</strong>: <a href=\"https://wandb.ai/maddonix/endomic/runs/2jba1ul2\" target=\"_blank\">https://wandb.ai/maddonix/endomic/runs/2jba1ul2</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2jba1ul2). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.27<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">youthful-bird-43</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/maddonix/endomic\" target=\"_blank\">https://wandb.ai/maddonix/endomic</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/maddonix/endomic/runs/1sc57z15\" target=\"_blank\">https://wandb.ai/maddonix/endomic/runs/1sc57z15</a><br/>\n",
       "                Run data is saved locally in <code>/home/lux_t1/Desktop/endo_audio_scaper/network/wandb/run-20210422_145835-1sc57z15</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train: Loss: 0.5979890397616795, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 1\n",
      "Train: Loss: 0.5595464110374451, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 2\n",
      "Train: Loss: 0.5434355352606092, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 3\n",
      "Train: Loss: 0.546835584299905, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 4\n",
      "Train: Loss: 0.540847625051226, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 5\n",
      "Train: Loss: 0.5362636872700283, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 6\n",
      "Train: Loss: 0.5395576570715223, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 7\n",
      "Train: Loss: 0.5478473135403225, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 8\n",
      "Train: Loss: 0.5476338182176862, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 9\n",
      "Train: Loss: 0.5347221664019993, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 10\n",
      "Train: Loss: 0.5442323684692383, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 11\n",
      "Train: Loss: 0.5410639217921666, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 12\n",
      "Train: Loss: 0.5257597608225686, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 13\n",
      "Train: Loss: 0.5352873163563865, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 14\n",
      "Train: Loss: 0.5324419523988452, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 15\n",
      "Train: Loss: 0.525825526033129, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 16\n",
      "Train: Loss: 0.5339017297540393, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 17\n",
      "Train: Loss: 0.5179239426340375, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 18\n",
      "Train: Loss: 0.530073310647692, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 19\n",
      "Train: Loss: 0.5226764891828809, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 20\n",
      "Train: Loss: 0.5152636851583209, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 21\n",
      "Train: Loss: 0.5162732601165771, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 22\n",
      "Train: Loss: 0.5210250956671578, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 23\n",
      "Train: Loss: 0.5084804083619799, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 24\n",
      "Train: Loss: 0.5218714347907475, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 25\n",
      "Train: Loss: 0.5150563631738935, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 26\n",
      "Train: Loss: 0.5140487466539655, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 27\n",
      "Train: Loss: 0.507543568100248, Accuracy: [0.37857143 0.38492063]\n",
      "Epoch: 28\n",
      "Train: Loss: 0.5167552190167564, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 29\n",
      "Train: Loss: 0.5054940155574253, Accuracy: [0.37936508 0.38333333]\n",
      "Epoch: 30\n",
      "Train: Loss: 0.504572434084756, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 31\n",
      "Train: Loss: 0.5108742245606014, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 32\n",
      "Train: Loss: 0.5031443876879556, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 33\n",
      "Train: Loss: 0.5040419740336282, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 34\n",
      "Train: Loss: 0.5032018295356205, Accuracy: [0.37857143 0.38333333]\n",
      "Epoch: 35\n",
      "Train: Loss: 0.4915442339011601, Accuracy: [0.37857143 0.38571429]\n",
      "Epoch: 36\n",
      "Train: Loss: 0.5069997310638428, Accuracy: [0.37936508 0.38333333]\n",
      "Epoch: 37\n",
      "Train: Loss: 0.48193404504231047, Accuracy: [0.37857143 0.38809524]\n",
      "Epoch: 38\n",
      "Train: Loss: 0.491924592426845, Accuracy: [0.37936508 0.38571429]\n",
      "Epoch: 39\n",
      "Train: Loss: 0.49159571528434753, Accuracy: [0.37777778 0.38253968]\n",
      "Epoch: 40\n",
      "Train: Loss: 0.48918780258723665, Accuracy: [0.38015873 0.38968254]\n",
      "Epoch: 41\n",
      "Train: Loss: 0.4924090121473585, Accuracy: [0.37857143 0.38650794]\n",
      "Epoch: 42\n",
      "Train: Loss: 0.4793409492288317, Accuracy: [0.38015873 0.38809524]\n",
      "Epoch: 43\n",
      "Train: Loss: 0.4801885187625885, Accuracy: [0.38253968 0.38571429]\n",
      "Epoch: 44\n",
      "Train: Loss: 0.47319132515362333, Accuracy: [0.38253968 0.39126984]\n",
      "Epoch: 45\n",
      "Train: Loss: 0.46609568170138765, Accuracy: [0.38571429 0.38730159]\n",
      "Epoch: 46\n",
      "Train: Loss: 0.4592714650290353, Accuracy: [0.38888889 0.39365079]\n",
      "Epoch: 47\n",
      "Train: Loss: 0.49455316577638897, Accuracy: [0.38095238 0.38730159]\n",
      "Epoch: 48\n",
      "Train: Loss: 0.4909734470503671, Accuracy: [0.38174603 0.39047619]\n",
      "Epoch: 49\n",
      "Train: Loss: 0.4632152318954468, Accuracy: [0.38015873 0.38650794]\n",
      "Epoch: 50\n",
      "Train: Loss: 0.4632406915937151, Accuracy: [0.38571429 0.3952381 ]\n",
      "Epoch: 51\n",
      "Train: Loss: 0.4698832929134369, Accuracy: [0.38412698 0.39285714]\n",
      "Epoch: 52\n",
      "Train: Loss: 0.4615176575524466, Accuracy: [0.39047619 0.3952381 ]\n",
      "Epoch: 53\n",
      "Train: Loss: 0.46115160414150785, Accuracy: [0.38253968 0.39603175]\n",
      "Epoch: 54\n",
      "Train: Loss: 0.4407193660736084, Accuracy: [0.40079365 0.39603175]\n",
      "Epoch: 55\n",
      "Train: Loss: 0.446140319108963, Accuracy: [0.38809524 0.4047619 ]\n",
      "Epoch: 56\n",
      "Train: Loss: 0.4441253457750593, Accuracy: [0.3968254  0.39126984]\n",
      "Epoch: 57\n",
      "Train: Loss: 0.43299814632960726, Accuracy: [0.38809524 0.4015873 ]\n",
      "Epoch: 58\n",
      "Train: Loss: 0.4134610721043178, Accuracy: [0.40238095 0.4015873 ]\n",
      "Epoch: 59\n",
      "Train: Loss: 0.40525772316115244, Accuracy: [0.4047619 0.4031746]\n",
      "Epoch: 60\n",
      "Train: Loss: 0.4131611500467573, Accuracy: [0.39603175 0.40714286]\n",
      "Epoch: 61\n",
      "Train: Loss: 0.40334733043398174, Accuracy: [0.40873016 0.4047619 ]\n",
      "Epoch: 62\n",
      "Train: Loss: 0.39420110838753836, Accuracy: [0.40634921 0.40555556]\n",
      "Epoch: 63\n",
      "Train: Loss: 0.3888410074370248, Accuracy: [0.41269841 0.41031746]\n",
      "Epoch: 64\n",
      "Train: Loss: 0.3768752004419054, Accuracy: [0.4031746  0.41269841]\n",
      "Epoch: 65\n",
      "Train: Loss: 0.37410418476377216, Accuracy: [0.41269841 0.41111111]\n",
      "Epoch: 66\n",
      "Train: Loss: 0.37164381997925894, Accuracy: [0.42301587 0.41825397]\n",
      "Epoch: 67\n",
      "Train: Loss: 0.361467570066452, Accuracy: [0.42063492 0.41666667]\n",
      "Epoch: 68\n",
      "Train: Loss: 0.3622156211308071, Accuracy: [0.41190476 0.41269841]\n",
      "Epoch: 69\n",
      "Train: Loss: 0.33948221802711487, Accuracy: [0.42222222 0.41746032]\n",
      "Epoch: 70\n",
      "Train: Loss: 0.35482004284858704, Accuracy: [0.40873016 0.41111111]\n",
      "Epoch: 71\n",
      "Train: Loss: 0.34135798045567106, Accuracy: [0.42142857 0.41507937]\n",
      "Epoch: 72\n",
      "Train: Loss: 0.347169748374394, Accuracy: [0.44047619 0.42936508]\n",
      "Epoch: 73\n",
      "Train: Loss: 0.32523285916873385, Accuracy: [0.42301587 0.41349206]\n",
      "Epoch: 74\n",
      "Train: Loss: 0.3228541314601898, Accuracy: [0.43888889 0.42301587]\n",
      "Epoch: 75\n",
      "Train: Loss: 0.31428938465459005, Accuracy: [0.43174603 0.42698413]\n",
      "Epoch: 76\n",
      "Train: Loss: 0.3174321140561785, Accuracy: [0.42539683 0.42142857]\n",
      "Epoch: 77\n",
      "Train: Loss: 0.2814824538571494, Accuracy: [0.44444444 0.43968254]\n",
      "Epoch: 78\n",
      "Train: Loss: 0.2805038924728121, Accuracy: [0.44126984 0.42936508]\n",
      "Epoch: 79\n",
      "Train: Loss: 0.26574947578566416, Accuracy: [0.44285714 0.42698413]\n",
      "Epoch: 80\n",
      "Train: Loss: 0.26447129036699024, Accuracy: [0.44444444 0.44126984]\n",
      "Epoch: 81\n",
      "Train: Loss: 0.2801050011600767, Accuracy: [0.45079365 0.42777778]\n",
      "Epoch: 82\n",
      "Train: Loss: 0.2584038185221808, Accuracy: [0.4531746  0.43809524]\n",
      "Epoch: 83\n",
      "Train: Loss: 0.26436502167156767, Accuracy: [0.44365079 0.43650794]\n",
      "Epoch: 84\n",
      "Train: Loss: 0.2650788000651768, Accuracy: [0.44285714 0.43968254]\n",
      "Epoch: 85\n",
      "Train: Loss: 0.23927509146077292, Accuracy: [0.45396825 0.43015873]\n",
      "Epoch: 86\n",
      "Train: Loss: 0.24127800124032156, Accuracy: [0.45       0.44365079]\n",
      "Epoch: 87\n",
      "Train: Loss: 0.22026941818850382, Accuracy: [0.4531746 0.4468254]\n",
      "Epoch: 88\n",
      "Train: Loss: 0.25678677431174685, Accuracy: [0.4547619  0.44920635]\n",
      "Epoch: 89\n",
      "Train: Loss: 0.2314676535981042, Accuracy: [0.46190476 0.45238095]\n",
      "Epoch: 90\n",
      "Train: Loss: 0.22013187195573533, Accuracy: [0.4547619  0.45238095]\n",
      "Epoch: 91\n",
      "Train: Loss: 0.22595512228352682, Accuracy: [0.45555556 0.4515873 ]\n",
      "Epoch: 92\n",
      "Train: Loss: 0.19261631795338222, Accuracy: [0.46190476 0.45079365]\n",
      "Epoch: 93\n",
      "Train: Loss: 0.1959888764790126, Accuracy: [0.46587302 0.4515873 ]\n",
      "Epoch: 94\n",
      "Train: Loss: 0.1953005897147315, Accuracy: [0.46746032 0.44920635]\n",
      "Epoch: 95\n",
      "Train: Loss: 0.2079832979610988, Accuracy: [0.46507937 0.45793651]\n",
      "Epoch: 96\n",
      "Train: Loss: 0.1979324413197381, Accuracy: [0.46428571 0.45396825]\n",
      "Epoch: 97\n",
      "Train: Loss: 0.2073068916797638, Accuracy: [0.46507937 0.45079365]\n",
      "Epoch: 98\n",
      "Train: Loss: 0.17612644604274205, Accuracy: [0.47380952 0.45714286]\n",
      "Epoch: 99\n",
      "Train: Loss: 0.17349982580968312, Accuracy: [0.45793651 0.46349206]\n",
      "Epoch: 100\n",
      "Train: Loss: 0.1561001581805093, Accuracy: [0.46746032 0.46587302]\n",
      "Epoch: 101\n",
      "Train: Loss: 0.15262384712696075, Accuracy: [0.46984127 0.46746032]\n",
      "Epoch: 102\n",
      "Train: Loss: 0.15005136281251907, Accuracy: [0.46666667 0.46190476]\n",
      "Epoch: 103\n",
      "Train: Loss: 0.14690557973725454, Accuracy: [0.47222222 0.45714286]\n",
      "Epoch: 104\n",
      "Train: Loss: 0.13412039833409445, Accuracy: [0.47142857 0.46825397]\n",
      "Epoch: 105\n",
      "Train: Loss: 0.14702758938074112, Accuracy: [0.48015873 0.47539683]\n",
      "Epoch: 106\n",
      "Train: Loss: 0.11511336266994476, Accuracy: [0.47936508 0.46984127]\n",
      "Epoch: 107\n",
      "Train: Loss: 0.17697502779109137, Accuracy: [0.4547619  0.45793651]\n",
      "Epoch: 108\n",
      "Train: Loss: 0.14863881255899156, Accuracy: [0.47460317 0.46190476]\n",
      "Epoch: 109\n",
      "Train: Loss: 0.1734141707420349, Accuracy: [0.4531746  0.47063492]\n",
      "Epoch: 110\n",
      "Train: Loss: 0.1379456605230059, Accuracy: [0.47301587 0.47301587]\n",
      "Epoch: 111\n",
      "Train: Loss: 0.12127085349389485, Accuracy: [0.46904762 0.46428571]\n",
      "Epoch: 112\n",
      "Train: Loss: 0.12008972253118243, Accuracy: [0.47857143 0.47539683]\n",
      "Epoch: 113\n",
      "Train: Loss: 0.12271470257214137, Accuracy: [0.47936508 0.46984127]\n",
      "Epoch: 114\n",
      "Train: Loss: 0.11258754187396594, Accuracy: [0.47142857 0.46984127]\n",
      "Epoch: 115\n",
      "Train: Loss: 0.1098947391978332, Accuracy: [0.47301587 0.47301587]\n",
      "Epoch: 116\n",
      "Train: Loss: 0.10938553139567375, Accuracy: [0.48333333 0.47539683]\n",
      "Epoch: 117\n",
      "Train: Loss: 0.1032717696258, Accuracy: [0.48492063 0.47619048]\n",
      "Epoch: 118\n",
      "Train: Loss: 0.11522729801280159, Accuracy: [0.48730159 0.47380952]\n",
      "Epoch: 119\n",
      "Train: Loss: 0.11557039831365858, Accuracy: [0.47063492 0.47619048]\n",
      "Epoch: 120\n",
      "Train: Loss: 0.13310045961822783, Accuracy: [0.48095238 0.46031746]\n",
      "Epoch: 121\n",
      "Train: Loss: 0.13149631236280715, Accuracy: [0.48412698 0.4547619 ]\n",
      "Epoch: 122\n",
      "Train: Loss: 0.11271126994064876, Accuracy: [0.47619048 0.48412698]\n",
      "Epoch: 123\n",
      "Train: Loss: 0.11601789402110237, Accuracy: [0.48095238 0.47301587]\n",
      "Epoch: 124\n",
      "Train: Loss: 0.14335270013128007, Accuracy: [0.46746032 0.46269841]\n",
      "Epoch: 125\n",
      "Train: Loss: 0.09870135251964841, Accuracy: [0.49126984 0.47063492]\n",
      "Epoch: 126\n",
      "Train: Loss: 0.10479126870632172, Accuracy: [0.47380952 0.48174603]\n",
      "Epoch: 127\n",
      "Train: Loss: 0.0955484328525407, Accuracy: [0.48968254 0.48174603]\n",
      "Epoch: 128\n",
      "Train: Loss: 0.09795803044523511, Accuracy: [0.48730159 0.47857143]\n",
      "Epoch: 129\n",
      "Train: Loss: 0.0833691656589508, Accuracy: [0.48253968 0.47936508]\n",
      "Epoch: 130\n",
      "Train: Loss: 0.09262840981994357, Accuracy: [0.49047619 0.48015873]\n",
      "Epoch: 131\n",
      "Train: Loss: 0.07697057723999023, Accuracy: [0.48888889 0.48095238]\n",
      "Epoch: 132\n",
      "Train: Loss: 0.08377451502851077, Accuracy: [0.48888889 0.48333333]\n",
      "Epoch: 133\n",
      "Train: Loss: 0.0604566436793123, Accuracy: [0.48968254 0.49365079]\n",
      "Epoch: 134\n",
      "Train: Loss: 0.07748438577566828, Accuracy: [0.48095238 0.48333333]\n",
      "Epoch: 135\n",
      "Train: Loss: 0.07123436140162605, Accuracy: [0.48650794 0.48809524]\n",
      "Epoch: 136\n",
      "Train: Loss: 0.06757615400212151, Accuracy: [0.49365079 0.48492063]\n",
      "Epoch: 137\n",
      "Train: Loss: 0.07383855325835091, Accuracy: [0.48968254 0.47698413]\n",
      "Epoch: 138\n",
      "Train: Loss: 0.061928934284618924, Accuracy: [0.4952381  0.48492063]\n",
      "Epoch: 139\n",
      "Train: Loss: 0.06378749119383949, Accuracy: [0.48412698 0.49126984]\n",
      "Epoch: 140\n",
      "Train: Loss: 0.0581111732338156, Accuracy: [0.48968254 0.49047619]\n",
      "Epoch: 141\n",
      "Train: Loss: 0.04016216764492648, Accuracy: [0.49126984 0.49206349]\n",
      "Epoch: 142\n",
      "Train: Loss: 0.04204443230160645, Accuracy: [0.4952381  0.49047619]\n",
      "Epoch: 143\n",
      "Train: Loss: 0.04041468272251742, Accuracy: [0.49444444 0.49206349]\n",
      "Epoch: 144\n",
      "Train: Loss: 0.04107974097132683, Accuracy: [0.49365079 0.49206349]\n",
      "Epoch: 145\n",
      "Train: Loss: 0.04206361249089241, Accuracy: [0.48888889 0.49285714]\n",
      "Epoch: 146\n",
      "Train: Loss: 0.06189128703304699, Accuracy: [0.49047619 0.48888889]\n",
      "Epoch: 147\n",
      "Train: Loss: 0.042212873697280884, Accuracy: [0.49047619 0.49206349]\n",
      "Epoch: 148\n",
      "Train: Loss: 0.04542536288499832, Accuracy: [0.4952381  0.49444444]\n",
      "Epoch: 149\n",
      "Train: Loss: 0.04584364300327642, Accuracy: [0.48412698 0.49444444]\n",
      "Epoch: 150\n",
      "Train: Loss: 0.0465256076838289, Accuracy: [0.4952381  0.49285714]\n",
      "Epoch: 151\n",
      "Train: Loss: 0.05449597883437361, Accuracy: [0.48888889 0.49047619]\n",
      "Epoch: 152\n",
      "Train: Loss: 0.2731629280107362, Accuracy: [0.44285714 0.45714286]\n",
      "Epoch: 153\n",
      "Train: Loss: 0.26975131886346, Accuracy: [0.45079365 0.45079365]\n",
      "Epoch: 154\n",
      "Train: Loss: 0.15126712088074004, Accuracy: [0.48174603 0.48095238]\n",
      "Epoch: 155\n",
      "Train: Loss: 0.13999624976090022, Accuracy: [0.47619048 0.47936508]\n",
      "Epoch: 156\n",
      "Train: Loss: 0.10357260704040527, Accuracy: [0.47698413 0.47777778]\n",
      "Epoch: 157\n",
      "Train: Loss: 0.07925273797341756, Accuracy: [0.49047619 0.48650794]\n",
      "Epoch: 158\n",
      "Train: Loss: 0.06231929787567684, Accuracy: [0.48730159 0.48888889]\n",
      "Epoch: 159\n",
      "Train: Loss: 0.04989280125924519, Accuracy: [0.48174603 0.49126984]\n",
      "Epoch: 160\n",
      "Train: Loss: 0.0451564858002322, Accuracy: [0.49365079 0.49444444]\n",
      "Epoch: 161\n",
      "Train: Loss: 0.03915386301066194, Accuracy: [0.49285714 0.49126984]\n",
      "Epoch: 162\n",
      "Train: Loss: 0.04499618070466178, Accuracy: [0.49444444 0.49365079]\n",
      "Epoch: 163\n",
      "Train: Loss: 0.039647318688886504, Accuracy: [0.49365079 0.49285714]\n",
      "Epoch: 164\n",
      "Train: Loss: 0.030384513416460583, Accuracy: [0.49047619 0.4984127 ]\n",
      "Epoch: 165\n",
      "Train: Loss: 0.04394083363669259, Accuracy: [0.4968254  0.48968254]\n",
      "Epoch: 166\n",
      "Train: Loss: 0.0527703267123018, Accuracy: [0.49365079 0.48650794]\n",
      "Epoch: 167\n",
      "Train: Loss: 0.07040210972939219, Accuracy: [0.49126984 0.48571429]\n",
      "Epoch: 168\n",
      "Train: Loss: 0.04835144297352859, Accuracy: [0.4952381  0.48412698]\n",
      "Epoch: 169\n",
      "Train: Loss: 0.036731328283037455, Accuracy: [0.49761905 0.49126984]\n",
      "Epoch: 170\n",
      "Train: Loss: 0.03234857826360634, Accuracy: [0.49444444 0.49047619]\n",
      "Epoch: 171\n",
      "Train: Loss: 0.02637878605829818, Accuracy: [0.4952381 0.4968254]\n",
      "Epoch: 172\n",
      "Train: Loss: 0.032042697604213445, Accuracy: [0.49444444 0.49206349]\n",
      "Epoch: 173\n",
      "Train: Loss: 0.02779817035687821, Accuracy: [0.49761905 0.4952381 ]\n",
      "Epoch: 174\n",
      "Train: Loss: 0.029751556925475597, Accuracy: [0.49444444 0.49365079]\n",
      "Epoch: 175\n",
      "Train: Loss: 0.030903215387037823, Accuracy: [0.49444444 0.49761905]\n",
      "Epoch: 176\n",
      "Train: Loss: 0.07437023759952613, Accuracy: [0.47857143 0.48968254]\n",
      "Epoch: 177\n",
      "Train: Loss: 0.05992927162774971, Accuracy: [0.48809524 0.49444444]\n",
      "Epoch: 178\n",
      "Train: Loss: 0.04634846826749189, Accuracy: [0.49126984 0.49047619]\n",
      "Epoch: 179\n",
      "Train: Loss: 0.05260034916656358, Accuracy: [0.48571429 0.49047619]\n",
      "Epoch: 180\n",
      "Train: Loss: 0.031198376656642983, Accuracy: [0.49603175 0.4952381 ]\n",
      "Epoch: 181\n",
      "Train: Loss: 0.02378334623894521, Accuracy: [0.4984127 0.4952381]\n",
      "Epoch: 182\n",
      "Train: Loss: 0.03968186862766743, Accuracy: [0.49365079 0.4952381 ]\n",
      "Epoch: 183\n",
      "Train: Loss: 0.1427341891186578, Accuracy: [0.46111111 0.47936508]\n",
      "Epoch: 184\n",
      "Train: Loss: 0.12605716926710947, Accuracy: [0.47460317 0.49285714]\n",
      "Epoch: 185\n",
      "Train: Loss: 0.057034471205302646, Accuracy: [0.48571429 0.49365079]\n",
      "Epoch: 186\n",
      "Train: Loss: 0.039705799892544746, Accuracy: [0.49365079 0.49285714]\n",
      "Epoch: 187\n",
      "Train: Loss: 0.031858389132789204, Accuracy: [0.49047619 0.49761905]\n",
      "Epoch: 188\n",
      "Train: Loss: 0.028449570227946554, Accuracy: [0.4952381 0.4952381]\n",
      "Epoch: 189\n",
      "Train: Loss: 0.026588532142341137, Accuracy: [0.49365079 0.49761905]\n",
      "Epoch: 190\n",
      "Train: Loss: 0.01927559037825891, Accuracy: [0.4968254  0.49365079]\n",
      "Epoch: 191\n",
      "Train: Loss: 0.025055466485874995, Accuracy: [0.49365079 0.4984127 ]\n",
      "Epoch: 192\n",
      "Train: Loss: 0.017356001771986485, Accuracy: [0.49603175 0.49761905]\n",
      "Epoch: 193\n",
      "Train: Loss: 0.013472550947751318, Accuracy: [0.49761905 0.49761905]\n",
      "Epoch: 194\n",
      "Train: Loss: 0.013486457256866353, Accuracy: [0.49761905 0.49920635]\n",
      "Epoch: 195\n",
      "Train: Loss: 0.020707491785287857, Accuracy: [0.4968254  0.49761905]\n",
      "Epoch: 196\n",
      "Train: Loss: 0.02960856697921242, Accuracy: [0.49047619 0.4968254 ]\n",
      "Epoch: 197\n",
      "Train: Loss: 0.02035484290016549, Accuracy: [0.4968254  0.49761905]\n",
      "Epoch: 198\n",
      "Train: Loss: 0.027213658339210918, Accuracy: [0.4968254  0.49761905]\n",
      "Epoch: 199\n",
      "Train: Loss: 0.029852001927793026, Accuracy: [0.4968254  0.48968254]\n",
      "Epoch: 200\n",
      "Train: Loss: 0.02907615713775158, Accuracy: [0.49761905 0.4968254 ]\n",
      "Epoch: 201\n",
      "Train: Loss: 0.018759578266846284, Accuracy: [0.49444444 0.49603175]\n",
      "Epoch: 202\n",
      "Train: Loss: 0.01641100538628442, Accuracy: [0.4968254 0.5      ]\n",
      "Epoch: 203\n",
      "Train: Loss: 0.014493861900908607, Accuracy: [0.4984127  0.49603175]\n",
      "Epoch: 204\n",
      "Train: Loss: 0.011373647022992373, Accuracy: [0.4984127  0.49920635]\n",
      "Epoch: 205\n",
      "Train: Loss: 0.014051950403622218, Accuracy: [0.49761905 0.4952381 ]\n",
      "Epoch: 206\n",
      "Train: Loss: 0.015537266486457415, Accuracy: [0.49761905 0.49761905]\n",
      "Epoch: 207\n",
      "Train: Loss: 0.016141972770648345, Accuracy: [0.49761905 0.49603175]\n",
      "Epoch: 208\n",
      "Train: Loss: 0.010838195315695234, Accuracy: [0.4984127 0.4984127]\n",
      "Epoch: 209\n",
      "Train: Loss: 0.01671518318887268, Accuracy: [0.4984127  0.49761905]\n",
      "Epoch: 210\n",
      "Train: Loss: 0.017982841469347477, Accuracy: [0.4952381 0.4968254]\n",
      "Epoch: 211\n",
      "Train: Loss: 0.01600455728891705, Accuracy: [0.49920635 0.4952381 ]\n",
      "Epoch: 212\n",
      "Train: Loss: 0.009188389139516013, Accuracy: [0.4984127 0.4984127]\n",
      "Epoch: 213\n",
      "Train: Loss: 0.018332469210560833, Accuracy: [0.4968254 0.4952381]\n",
      "Epoch: 214\n",
      "Train: Loss: 0.016362427534269437, Accuracy: [0.49761905 0.49920635]\n",
      "Epoch: 215\n",
      "Train: Loss: 0.023512597594942366, Accuracy: [0.49761905 0.4952381 ]\n",
      "Epoch: 216\n",
      "Train: Loss: 0.05414308487836804, Accuracy: [0.49206349 0.49126984]\n",
      "Epoch: 217\n",
      "Train: Loss: 0.038926713700805395, Accuracy: [0.49365079 0.49206349]\n",
      "Epoch: 218\n",
      "Train: Loss: 0.026348871578063284, Accuracy: [0.4968254  0.49444444]\n",
      "Epoch: 219\n",
      "Train: Loss: 0.02132484396653516, Accuracy: [0.49603175 0.49444444]\n",
      "Epoch: 220\n",
      "Train: Loss: 0.020989625249058008, Accuracy: [0.4952381 0.4984127]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5b6462fb2e12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-0dfc20862e92>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dl, num_epochs, classes)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#             print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/endomic/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1013\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1014\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1015\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1016\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/endomic/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         return F.binary_cross_entropy_with_logits(input, target,\n\u001b[0m\u001b[1;32m    715\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/endomic/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2911\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2913\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_dl, 1000, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c64c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = ['Alarm_bell_ringing', 'Cat', 'Dishes', 'Dog', 'Electric_shaver_toothbrush']\n",
    "classes = [\"Cat\", \"Dog\"]\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config = {\n",
    "    \"sample_rate\": 44100,\n",
    "    \"n_mels\": 64,\n",
    "    \"n_fft\": 1024, \n",
    "    \"hop_len\": 512,\n",
    "    \"top_db\": 80,\n",
    "    \"n_mfcc\": 64,\n",
    "    \"classes\": classes,\n",
    "    \"data_path\": \"../scaper/soundscapes/train\",\n",
    "    \"duration\": 10000\n",
    "}\n",
    "\n",
    "df, classes = utils.get_dataset_dataframe(config[\"data_path\"])\n",
    "dataset = utils.SoundDataSet(df, **config)\n",
    "# Train / Val Split\n",
    "\n",
    "num_items = len(dataset)\n",
    "print(num_items)\n",
    "num_train = round(num_items * 0.9)\n",
    "num_val = num_items - num_train\n",
    "batch_size = 10\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [num_train, num_val])\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02994462",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(fc.in_features, 2, bias = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2646aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine input channels:\n",
    "model.conv1=nn.Conv2d(1, model.conv1.out_channels, kernel_size=model.conv1.kernel_size[0], \n",
    "                      stride=model.conv1.stride[0], padding=model.conv1.padding[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "base_lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba05a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = base_lr, momentum = 0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = num_epochs//3, gamma = 0.1)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project='endomic', entity='maddonix')\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408352e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal(signal, title, cmap=None):\n",
    "    fig = plt.figure()\n",
    "    if signal.ndim == 1:\n",
    "        plt.plot(signal)\n",
    "    else:\n",
    "        plt.imshow(signal, cmap=cmap)    \n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab7bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.type_as(outputs))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        iteration = epoch * len(train_loader) + batch_idx\n",
    "        if batch_idx % log_interval == 0: #print training stats\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'\n",
    "                  .format(epoch, batch_idx * len(inputs), len(train_loader.dataset), \n",
    "                          100. * batch_idx / len(train_loader), loss))\n",
    "            wandb.log({\n",
    "                \"train_loss\": loss,\n",
    "                \"learning rate\": optimizer.param_groups[0]['lr']\n",
    "            }) \n",
    "                \n",
    "        \n",
    "        if batch_idx % debug_interval == 0:    # report debug image every \"debug_interval\" mini-batches\n",
    "            for n, (inp, pred, label) in enumerate(zip(inputs, predicted, labels)):\n",
    "                series = 'label_{}_pred_{}'.format(classes[label.cpu()], classes[pred.cpu()])\n",
    "                print('Train MelSpectrogram samples/{}_{}_{}'.format(batch_idx, n, series))\n",
    "                plot_signal(inp.cpu().numpy().squeeze(), series, 'hot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b624ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for idx, (sounds, sample_rate, inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            prediction = outputs.copy()\n",
    "            prediction[prediction>0.5] = 1\n",
    "            prediction[prediction<=0.5] = 0\n",
    "            \n",
    "            # Count of predictions that matched the target label\n",
    "            c += (prediction == labels).sum(axis = 0).cpu().numpy()\n",
    "\n",
    "            for i in range(len(inputs)):\n",
    "                label = labels[i].item()\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "        \n",
    "            iteration = (epoch + 1) * len(train_loader)\n",
    "            if idx % debug_interval == 0:    # report debug image every \"debug_interval\" mini-batches\n",
    "                for n, (sound, inp, pred, label) in enumerate(zip(sounds, inputs, predicted, labels)):\n",
    "                    series = 'label_{}_pred_{}'.format(classes[label.cpu()], classes[pred.cpu()])\n",
    "                    print('Test audio samples/{}_{}_{}'.format(idx, n, series), \n",
    "                                                 sound, iteration, int(sample_rate[n]))\n",
    "                    print('Test MelSpectrogram samples/{}_{}_{}'.format(idx, n, series))\n",
    "                    plot_signal(inp.cpu().numpy().squeeze(), series, 'hot')\n",
    "\n",
    "    total_accuracy = 100 * sum(class_correct)/sum(class_total)\n",
    "    print('[Iteration {}] Accuracy on the {} test images: {}%\\n'.format(epoch, sum(class_total), total_accuracy))\n",
    "    wandb.log({\n",
    "                \"accuracy/total\": total_accuracy\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b3dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 10\n",
    "debug_interval = 25\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, epoch)\n",
    "    test(model, epoch)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8102052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
